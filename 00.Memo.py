# ğŸ§­ğŸ§­ğŸ§­ df[row][col] | df.loc[row, col] | df.iloc[row, col]


# ğŸ§­ loc is better for human-readable analysis locæ›´é€‚ç”¨äºæ–‡æœ¬å½¢å¼åˆ†æ -> .loc[row, col]
# ğŸ§­ If there is ONLY one filter dimension -> use df[filter] directly! å¦‚æœåªæœ‰ä¸€ä¸ªç»´åº¦çš„è¿‡æ»¤ï¼Œç›´æ¥ä½¿ç”¨df[filter]
# ğŸ§­ .loc is the ultimate way of re-setting indexes -> df.loc[row, col] -> df.loc[x, y]

# ğŸ§­ split -> Apply function -> Combine Results (https://youtu.be/txMdrV1Ut64?t=817)

"""
# ğŸ§­ NOTE: replace / rename / map MUST come with {dict-format}!

df.rename(columns={})
df.drop(columns=[])  # BE CAUTIOUS when dropping any data!
"""

# ğŸ§­ Each column first of all a Serie, and a 1-dimensional DataFrame! åˆ—å³ä¸€ç»´DF

# ğŸ§­ Recommended secure way to locate ONLY numeric columns ä¾¿æ·ç¨³å¥çš„ç­›é€‰æ•°æ®åˆ—çš„æ–¹æ³•
# ğŸ§  df.select_dtypes(include=np.number) -> include=np.number

# ğŸ§­ As long as it is a Data Frame, we can always apply filter åªè¦æ˜¯DFå°±å¯ä»¥ä½¿ç”¨T/Fè¿›è¡Œè¿‡æ»¤


# Concatenate - https://youtu.be/txMdrV1Ut64?t=2131 â­ï¸ -> NO.08

# ğŸ¯ how to deal with NaN with the entire DF æ•´ä½“æ€§å¤„ç†æ‰€æœ‰çš„NaN

# â­ï¸ Missing valuves over 10% cut-off

# df.isnull().mean().sort_values(ascending=False)#[:'LastHireDate'].index.tolist()

# ğŸ§  â­ï¸ fillna("")

# df.select_dtypes(include=object).fillna('').applymap(str.upper)


"""
# ğŸ§­ Append can even append to BOTH rows and columns all at once - the ultimate way of adding data as NoSQL style
# Append å¯ä»¥åŒæ—¶ä»¥ä¸å®šé¡¹å½¢å¼ï¼Œ2ç»´æ·»åŠ è¡Œåˆ—ï¼Œéå¸¸é€‚åˆä¸å®šé¡¹çš„NoSqlæ¨¡å¼

# ğŸ§  df.append({dict}, ignore_index=True) -> ignore_index=True

df = df.append({
    'name': 'Adam Smith',
    'first': 'Joseph',
    'last': 'Yu',
    'email': 'JosephYu@gmail.com',
    }, ignore_index=True)


df.drop(
    index= ,
    columns= ,
)


"""


"""


# ğŸ§­ Replace is in most cases the best solution -> it gives you the option of trila and then use inplace=True to let it happen
# replace æ˜¯é€šå¸¸å¢ƒå†µä¸‹æœ€åˆé€‚çš„é€‰æ‹©ï¼ç°å®éªŒï¼Œå¦‚ä½•å¯è¡Œå†åº”ç”¨ï¼Œè€Œä¸ç›´æ¥å½±å“åŸå§‹æ•°æ®ï¼

# ğŸ§­ Replace 1 value ONLY -> replace(a, b)
# ğŸ§­ Replace 2 or more values -> replace({dict})

df['first'].replace({
    'Corey': 'Mark_1',
    'Jane': 'Mark_2',
    'John': 'Mark_3'}, 
    inplace=True)
"""

"""
# â­ï¸ Mass create new rows into existing colums æ‰¹é‡æ·»åŠ æ–°è¡Œå¹¶å…¥å·²æœ‰æ•°æ®

for i in range(11, 21, 1):
    df.loc[i] = {
    'First_Name':'Joseph',
    'Last_Name':'Yu',
    'Email_Address':'josephyu@outlook.com'
    }
"""


"""

so for example
we can parse out the median salaries for
these developer types what programming
languages have the highest job
satisfaction what the most preferred
development environment is for the
different development types and
languages

"""


"""
ğŸ§­ dtypes issues â­ï¸ -> NO.09

    1. df.dtypes -> check the ENTIRE df for potential conflicts æ•´ä½“è€ƒå¯Ÿæ‰€æœ‰colçš„å¯¹åº”æ•°æ®ç±»å‹

    2. na_values = ['NA', 'na', 'Missing'] when forming the dataframe å°½å¯èƒ½å°†ä½œä¸ºstringå‡ºç°çš„Naç±»å‹æ‰¹é‡æ›¿æ¢æˆçœŸæ­£çš„NaN/None/np.nan

        df = pd.read_csv(survey_source, na_values=na_values)  # index_col = 'Respondent' ä¼˜åŒ–åšæ³•æ˜¯åœ¨è¯»å–æ—¶å°±æ¸…æ´—å®Œæ¯•ï¼

    3. Finally focus on the remaing text to replace manually æœ€åé’ˆå¯¹ä¸ªåˆ«æ–‡æœ¬é€ä¸ªæ›¿æ¢

        df['YearsCode'].replace({'Less than 1 year':'0', 'More than 50 years':'51'}, inplace=True)
        df['YearsCodePro'].replace({'Less than 1 year':'0', 'More than 50 years':'51'}, inplace=True)


"""
# df['Hobbyist'].replace({'Yes': 1, 'No': 0})


"""
filter = (df['Date'] < '2020') & (df['Date'] >= '2019')  # Recommende for simplicity ğŸ‘ğŸ‘ğŸ‘

# å¿«é€Ÿä»¥å¹´ä¸ºå•ä½ï¼Œæ™’å‡ºéœ€è¦çš„æ¯ä¸€ç¬”äº¤æ˜“

Date	Symbol	Open	High	Low	Close	Volume	DayOfWeek
1749	2019-12-31 23:00:00	ETHUSD	128.33	128.69	128.14	128.54	440678.91	Tuesday
1750	2019-12-31 22:00:00	ETHUSD	128.38	128.69	127.95	128.33	554646.02	Tuesday
1751	2019-12-31 21:00:00	ETHUSD	127.86	128.43	127.72	128.38	350155.69	Tuesday
1752	2019-12-31 20:00:00	ETHUSD	127.84	128.34	127.71	127.86	428183.38	Tuesday
1753	2019-12-31 19:00:00	ETHUSD	128.69	128.69	127.60	127.84	1169847.84	Tuesday
...	...	...	...	...	...	...	...	...
10504	2019-01-01 04:00:00	ETHUSD	130.75	133.96	130.74	131.96	2791135.37	Tuesday
10505	2019-01-01 03:00:00	ETHUSD	130.06	130.79	130.06	130.75	503732.63	Tuesday
10506	2019-01-01 02:00:00	ETHUSD	130.79	130.88	129.55	130.06	838183.43	Tuesday
10507	2019-01-01 01:00:00	ETHUSD	131.62	131.62	130.77	130.79	434917.99	Tuesday
10508	2019-01-01 00:00:00	ETHUSD	130.53	131.91	130.48	131.62	1067136.21	Tuesday

8760 rows Ã— 8 columns

"""


"""
String series:

df[].str.contains()
df[].str.replace()
df[].str.upper()
df[].str.lower()
df[].str.split()


# ğŸ¯ å¯¹æ”¶å…¥è¿›è¡Œç±»ä¼¼ç™¾åˆ†æ¯”çš„åˆ†æ®µå¼æˆªå–
# ğŸ¯ æ ¹æ®high salaryè¿‡æ»¤ï¼Œè·å¾—å„ä¸ªå›½å®¶é«˜è–ªå²—ä½åˆ†å¸ƒå›¾

df['SocialMedia'].value_counts(normalize=True)*100

Reddit                      17.023343
YouTube                     16.379076
WhatsApp                    15.807051
Facebook                    15.606902
Twitter                     13.498822
Instagram                    7.414996
I don't use social media     6.577685
LinkedIn                     5.330602

"""

"""
# 200 - Check if there is ANY space from column names
count = 0

for i in df.columns.values.tolist():
    if ' ' in i:
        count += 1

print(count)
"""
